{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed16bcf7-37a9-444c-899a-846369c9ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from moviepy import VideoFileClip, AudioFileClip\n",
    "import imageio.v3 as iio\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17c352f-d6fc-4310-a086-03613eda03da",
   "metadata": {},
   "source": [
    "# A lot of functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6d9a61-7e5c-405b-9980-3fe534d5dabe",
   "metadata": {},
   "source": [
    "## Saving video as frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556355d6-389d-4da3-b881-2bd89a37d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_video_as_frames(video, video_frames_path, id_length):\n",
    "\n",
    "    if not os.path.exists(video_frames_path):\n",
    "        os.makedirs(video_frames_path)\n",
    "\n",
    "    pbar = tqdm()\n",
    "    \n",
    "    vidcap = cv2.VideoCapture(video)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0\n",
    "    while success:\n",
    "        image_id = '0' * (id_length - len(str(count))) + str(count)\n",
    "        frame_path = osp.join(video_frames_path, 'frame_{}.png'.format(image_id))\n",
    "        cv2.imwrite(frame_path, image)\n",
    "        success,image = vidcap.read()\n",
    "        count += 1\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bd774-26ee-4bc5-82de-d83715bd972b",
   "metadata": {},
   "source": [
    "## Finding voting ballot box corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f1e0dcd-0ac0-4500-a46c-24c310f0e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_coordinates(file_path):\n",
    "\n",
    "    coordinates = []\n",
    "    file = open(file_path,'r')\n",
    "    while True:\n",
    "        content=file.readline()\n",
    "        if not content:\n",
    "            break\n",
    "        coordinates = [ int(float(x)) for x in content.strip().split(\" \") ]\n",
    "    file.close()\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def save_corner_coordinates(coordinates, labels_path, file_name):\n",
    "\n",
    "    file_path = os.path.join(labels_path, file_name)\n",
    "\n",
    "    with open(file_path, \"w\") as file:\n",
    "        file.write(str(coordinates[0][0][0]) + \" \" + str(coordinates[0][0][1]) + \" \" + \n",
    "                   str(coordinates[1][0][0]) + \" \" + str(coordinates[1][0][1]) + \" \" + \n",
    "                   str(coordinates[2][0][0]) + \" \" + str(coordinates[2][0][1]) + \" \" + \n",
    "                   str(coordinates[3][0][0]) + \" \" + str(coordinates[3][0][1]))\n",
    "        file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "457000ce-4aee-4203-bc6c-8659a3da1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_video(input_video_frames: str, \n",
    "                       labels_path: str,\n",
    "                       maxCorners: int, \n",
    "                       startFeatures):\n",
    "\n",
    "    if not os.path.exists(labels_path):\n",
    "        os.makedirs(labels_path)\n",
    "\n",
    "    # Find video frames\n",
    "    frames = sorted([file for file in os.listdir(input_video_frames) if file.split(\".\")[1] == \"png\"])\n",
    "\n",
    "    # First frame\n",
    "    frame_path = os.path.join(input_video_frames, frames[0])\n",
    "    old_frame = cv2.imread(frame_path)\n",
    "    frame_width = old_frame.shape[1]\n",
    "    frame_height = old_frame.shape[0]\n",
    "\n",
    "    # Initial corners\n",
    "    old_frame_gs = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY) # Grayscale\n",
    "    mask_linestring = np.zeros_like(old_frame, dtype=np.uint8) # create a mask for optical flow\n",
    "    p0 = startFeatures # initial corners\n",
    "    save_corner_coordinates(p0, labels_path, frames[0].split('.')[0]+str(\".txt\"))\n",
    "\n",
    "    # Going through all the frames\n",
    "    for i in tqdm(range(1, len(frames))):\n",
    "        frame_path = os.path.join(input_video_frames, frames[i])\n",
    "        new_frame = cv2.imread(frame_path)\n",
    "        new_frame_gs = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY)\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(old_frame_gs, new_frame_gs, p0, None, (3,3))\n",
    "        save_corner_coordinates(p1, labels_path, frames[i].split('.')[0]+str(\".txt\"))\n",
    "\n",
    "        # make new frame the old one\n",
    "        old_frame_gs = new_frame_gs.copy()\n",
    "        p0 = p1.reshape(-1,1,2)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb6d7e1-c43e-4952-9856-2dcc6166c44b",
   "metadata": {},
   "source": [
    "## Yolo predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a577df21-4f57-4212-bfc2-89d941b51b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracking_with_bounding_boxes(model, video_frames_path, video_bboxes_path, tracked_labels_path, add_to_boxes_width, add_to_boxes_height):\n",
    "\n",
    "    first_3_not_found = True\n",
    "    first_3_index = 0\n",
    "\n",
    "    if not os.path.exists(video_bboxes_path):\n",
    "        os.makedirs(video_bboxes_path)\n",
    "\n",
    "    frames = [img for img in os.listdir(video_frames_path) if img.endswith(\".png\")]\n",
    "    frames.sort()\n",
    "\n",
    "    for i in range(len(frames)):\n",
    "        frame_path = osp.join(video_frames_path, frames[i])\n",
    "        frame = cv2.cvtColor(cv2.imread(frame_path), cv2.COLOR_BGR2RGB)\n",
    "        height, width, channels = frame.shape\n",
    "    \n",
    "        results = model.track(frame, \n",
    "                              imgsz = 1920,\n",
    "                              conf = 0.2,\n",
    "                              iou = 0.8,\n",
    "                              persist=True)\n",
    "\n",
    "        classes = np.array(results[0].boxes.cls.cpu())\n",
    "        bboxes = np.array(results[0].boxes.xywhn.cpu())\n",
    "        frame_labels = np.array([np.insert(bboxes[i], 0, classes[i]) for i in range(len(bboxes))])\n",
    "\n",
    "        \n",
    "        # Reading in box corner info\n",
    "        labels_path = os.path.join(tracked_labels_path, frames[i].replace(\"png\", \"txt\"))\n",
    "        corner_labels = read_in_coordinates(labels_path)\n",
    "\n",
    "        x_coord = [corner_labels[j] for j in range(0, len(corner_labels), 2)]\n",
    "        y_coord = [corner_labels[j+1] for j in range(0, len(corner_labels)-1, 2)]\n",
    "        xmin, xmax, ymin, ymax = min(x_coord)/width, max(x_coord)/width, min(y_coord)/height, max(y_coord)/height\n",
    "\n",
    "        \n",
    "        # Going through and filtering YOLO results\n",
    "        filtered_labels = []\n",
    "        for j in range(len(frame_labels)):\n",
    "\n",
    "            bounding_box = frame_labels[j]\n",
    "            if bounding_box[1] > xmin and bounding_box[1] < xmax and bounding_box[2] > ymin and bounding_box[2] < ymax:\n",
    "\n",
    "                if len(filtered_labels) == 0:\n",
    "                    filtered_labels.append(frame_labels[j]) \n",
    "                else:\n",
    "                    new_object = True\n",
    "                    for k in range(j):\n",
    "                        diffrence = abs(frame_labels[j][1] - frame_labels[k][1])\n",
    "                        if diffrence <= 0.001:\n",
    "                            new_object = False\n",
    "                            break\n",
    "                    if new_object: # Only adding this bounding box if it actually is a new digit and not very close prediction to already existing digit\n",
    "                        filtered_labels.append(frame_labels[j])\n",
    "\n",
    "        \n",
    "        if len(filtered_labels) == 3 and first_3_not_found: # Finding the first frame where we have found all 3 digits \n",
    "            first_3_index = i\n",
    "            first_3_not_found = False\n",
    "\n",
    "        found_bboxes = min(len(filtered_labels), 3) # Only saving the first 3 digits\n",
    "\n",
    "        labels_file_name = frames[i].replace(\"frame\", \"bboxes\").replace(\"png\", \"txt\")\n",
    "        labels_path = osp.join(video_bboxes_path, labels_file_name)\n",
    "\n",
    "        add_width = add_to_boxes_width / width\n",
    "        add_height = add_to_boxes_height / height\n",
    "        \n",
    "        # write the label and bounding boxes\n",
    "        if found_bboxes == 0:\n",
    "            with open(labels_path, \"w\") as file:\n",
    "                pass \n",
    "        else:\n",
    "            with open(labels_path, \"w\") as file:\n",
    "                for j in range(found_bboxes):\n",
    "                    file.write(str(int(filtered_labels[j][0])) + \" \" +\n",
    "                           str(float(filtered_labels[j][1])) + \" \" + \n",
    "                           str(float(filtered_labels[j][2])) + \" \" + \n",
    "                           str(float(filtered_labels[j][3]) + add_width ) + \" \" + \n",
    "                           str(float(filtered_labels[j][4]) + add_height ) + \"\\n\")\n",
    "                file.close()  \n",
    "\n",
    "\n",
    "    return first_3_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5523e0-74e0-4d64-82b5-8e9e77f512bb",
   "metadata": {},
   "source": [
    "## Reading and saving label info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb60aaed-1e49-46df-be8f-6c656825f307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_in_bbox_txt_file(bbox_path) :\n",
    "    bboxes = []\n",
    "    file = open(bbox_path,'r')\n",
    "    while True:\n",
    "        content=file.readline()\n",
    "        if not content:\n",
    "            break\n",
    "        elements = [ float(x) for x in content.strip().split(\" \") ]\n",
    "        bboxes.append(elements)\n",
    "    file.close()\n",
    "\n",
    "    if len(bboxes) != 0:\n",
    "        sorted_indices = np.argsort(np.array(bboxes)[:, 1]) # Based on xcenter\n",
    "        return np.array(bboxes)[sorted_indices]\n",
    "    else:\n",
    "        return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7913a8cb-550e-4fe7-a8d6-6e550309c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_bboxes_into_txt(path, bboxes):\n",
    "    if len(bboxes) == 0:\n",
    "        with open(path, \"w\") as file:\n",
    "            pass \n",
    "    else:\n",
    "        with open(path, \"w\") as file:\n",
    "            for j in range(len(bboxes)):\n",
    "                if len(bboxes[j]) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    file.write(str(int(bboxes[j][0])) + \" \" +\n",
    "                           str(float(bboxes[j][1])) + \" \" + \n",
    "                           str(float(bboxes[j][2])) + \" \" + \n",
    "                           str(float(bboxes[j][3])) + \" \" + \n",
    "                           str(float(bboxes[j][4])) + \"\\n\")\n",
    "            file.close()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d1821-c68b-4f78-9fa2-ff95e939c164",
   "metadata": {},
   "source": [
    "## Creating frames algorithmically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b04de9f-9da7-4f38-abab-405aa669c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def creating_missing_bboxes(yolo_boxes_path, bboxes_path, first_3_idx, id_length):\n",
    "\n",
    "    bboxes_files = [f for f in os.listdir(yolo_boxes_path) if f.endswith('.txt')]\n",
    "    bboxes_files.sort()\n",
    "    bboxes_3_labels = []\n",
    "    last_x = [0, 0, 0]\n",
    "    prediction_next = [0, 0, 0]\n",
    "\n",
    "    if not os.path.exists(bboxes_path):\n",
    "        os.makedirs(bboxes_path)\n",
    "\n",
    "\n",
    "    print(\"Creating 3 bbox spaces for every frame\")\n",
    "    for i in tqdm(range(len(bboxes_files))):\n",
    "\n",
    "        frame_label_path = osp.join(yolo_boxes_path, bboxes_files[i])\n",
    "        frame_bboxes = reading_in_bbox_txt_file(frame_label_path)\n",
    "    \n",
    "        if i < first_3_idx: # Before the first 3-digit frame, just save the bounding box info\n",
    "            bboxes_3_labels.append(frame_bboxes)\n",
    "        elif i == first_3_idx: # Save info about the 3-digits\n",
    "            bboxes_3_labels.append(frame_bboxes)\n",
    "            last_x = [frame_bboxes[0][1], frame_bboxes[1][1], frame_bboxes[2][1]]\n",
    "            prediction_next = [frame_bboxes[0][1], frame_bboxes[1][1], frame_bboxes[2][1]]\n",
    "        else:\n",
    "            if len(frame_bboxes) == 0: # Frame empty, but save 3 arrays\n",
    "                bboxes_3_labels.append([[], [], []])\n",
    "            elif len(frame_bboxes) == 3: # All digits found\n",
    "                bboxes_3_labels.append(frame_bboxes)\n",
    "                prediction_next = [frame_bboxes[0][1] + (frame_bboxes[0][1] - last_x[0]), \n",
    "                                   frame_bboxes[1][1] + (frame_bboxes[1][1] - last_x[1]), \n",
    "                                   frame_bboxes[2][1] + (frame_bboxes[2][1] - last_x[2]) ]\n",
    "                last_x = [frame_bboxes[0][1],frame_bboxes[1][1], frame_bboxes[2][1] ]\n",
    "            else: # 1 or 2 digits found\n",
    "                new_bbox = [[], [], []]\n",
    "                prediction = [prediction_next[0] + (prediction_next[0] - last_x[0]),\n",
    "                              prediction_next[1] + (prediction_next[1] - last_x[1]),\n",
    "                              prediction_next[2] + (prediction_next[2] - last_x[2])]\n",
    "                    \n",
    "                for j in range(len(frame_bboxes)): # Find to which digit this bounding box info belongs to\n",
    "                    digit = frame_bboxes[j]\n",
    "                    differences = abs(prediction_next - frame_bboxes[j][1])\n",
    "                    min_index = min(range(len(differences)), key=differences.__getitem__)\n",
    "                    new_bbox[min_index] = digit\n",
    "                    prediction[min_index] = digit[1] + (digit[1] - last_x[min_index])\n",
    "                    last_x[min_index] = digit[1]\n",
    "                prediction_next = prediction\n",
    "                bboxes_3_labels.append(new_bbox)\n",
    "\n",
    "\n",
    "    print(\"Creating missing bboxes\")\n",
    "    for i in range(3): # Going through every digit object\n",
    "        pbar = tqdm(total = len(bboxes_3_labels)-1)\n",
    "\n",
    "        j = first_3_idx\n",
    "        while j < len(bboxes_3_labels)-1:\n",
    "            pbar.update(1)\n",
    "\n",
    "            digit = bboxes_3_labels[j][i] # Starting digit\n",
    "            for k in range(j+1, len(bboxes_3_labels)): # Going through next frames\n",
    "                if len(bboxes_3_labels[k][i]) == 0: # Model didn't find digit from this frame\n",
    "                    if k >= len(bboxes_3_labels)-1:\n",
    "                        j = k\n",
    "                        break\n",
    "                    continue\n",
    "                else: # (some) next frame has this digit\n",
    "                    if j + 1 == k: # We found digit from next frame\n",
    "                        j += 1\n",
    "                        break\n",
    "                    elif k >= len(bboxes_3_labels)-1:\n",
    "                        j = k\n",
    "                        break\n",
    "                    else: # We found digit somewhere further away\n",
    "                        if k-j < 50:\n",
    "                            # We generate bboxes\n",
    "                            generate_frames_nr = k-j-1\n",
    "                            for m in range(1, generate_frames_nr + 1):\n",
    "                                new_frame = [digit[0],\n",
    "                                            digit[1] + ((bboxes_3_labels[k][i][1] - digit[1]) / generate_frames_nr * m),\n",
    "                                            digit[2] + ((bboxes_3_labels[k][i][2] - digit[2]) / generate_frames_nr * m),\n",
    "                                            digit[3] + ((bboxes_3_labels[k][i][3] - digit[3]) / generate_frames_nr * m),\n",
    "                                            digit[4] + ((bboxes_3_labels[k][i][4] - digit[4]) / generate_frames_nr * m)\n",
    "                                            ]\n",
    "                                bboxes_3_labels[j+m][i] = new_frame\n",
    "                        j = k\n",
    "                        break\n",
    "\n",
    "    # Saving new bounding boxes\n",
    "    for i in range(len(bboxes_3_labels)):\n",
    "        image_id = '0' * (id_length - len(str(i))) + str(i)\n",
    "        labels_path = osp.join(bboxes_path, \"bboxes_{}.txt\".format(image_id))\n",
    "        save_bboxes_into_txt(labels_path, bboxes_3_labels[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476e51b7-6d00-4685-81fe-73664d298c04",
   "metadata": {},
   "source": [
    "## Changing the digits in the frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff840c3-4461-4f9a-a1b8-a156dbc19324",
   "metadata": {},
   "source": [
    "### Getting digits from the frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87fe17af-281d-4c65-920b-fea7581ece52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finding_digits_from_the_frame(frame, frame_width, frame_height, frame_labels, padding_up_down, padding_sides):\n",
    "    \n",
    "    digits = []\n",
    "    \n",
    "    for i in range(len(frame_labels)):\n",
    "        digit_width = int(frame_labels[i][3] * frame_width) + padding_sides # Adding more pixels for a boundary\n",
    "        digit_height = int(frame_labels[i][4] * frame_height) + padding_up_down\n",
    "        xmin = int((frame_labels[i][1] * frame_width) - digit_width/2)\n",
    "        ymin = int((frame_labels[i][2] * frame_height) - digit_height/2)\n",
    "    \n",
    "        digit = frame[ymin:ymin+digit_height, xmin:xmin+digit_width]\n",
    "        digits.append(digit)\n",
    "\n",
    "    return digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98af5c29-576f-4fba-9983-c2cac82cc2c5",
   "metadata": {},
   "source": [
    "### Making the digits into a squares (aka creating more background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7609686c-79fe-4463-ae23-0e81ac3b67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changing_digit_into_square(digits, square_digits_path, frame_id, padding_up_down, padding_sides):\n",
    "\n",
    "    if not os.path.exists(square_digits_path):\n",
    "        os.makedirs(square_digits_path)\n",
    "    if not os.path.exists(osp.join(square_digits_path, \"0\")):\n",
    "        os.makedirs(osp.join(square_digits_path, \"0\"))\n",
    "    if not os.path.exists(osp.join(square_digits_path, \"1\")):\n",
    "        os.makedirs(osp.join(square_digits_path, \"1\"))\n",
    "    if not os.path.exists(osp.join(square_digits_path, \"2\")):\n",
    "        os.makedirs(osp.join(square_digits_path, \"2\"))\n",
    "        \n",
    "    \n",
    "    for i in range(len(digits)):\n",
    "    \n",
    "        digit = digits[i]\n",
    "        digit_width, digit_height = digit.shape[1], digit.shape[0]\n",
    "        square_hw = max(digit_width, digit_height)\n",
    "        square = np.zeros((square_hw, square_hw, 3), dtype=int)\n",
    "    \n",
    "        bigger_height = True if digit_width <= digit_height else False\n",
    "        mask_xmin, mask_ymin, mask_width, mask_height = 0, 0, 0, 0\n",
    "\n",
    "        # When the digit is tall and we have to extend the sides.\n",
    "        if bigger_height:\n",
    "            small_bg = digit[0:digit_height, 0:10]\n",
    "            for j in range(0, square_hw, 10):\n",
    "                if math.floor(square_hw/10)*10 == j: # last part to cover \n",
    "                    new_bg_width = square_hw%10 \n",
    "                    small_bg = digit[0:digit_height, 0:new_bg_width]\n",
    "                    square[0:digit_height, j:j+new_bg_width] = small_bg\n",
    "                else:\n",
    "                    square[0:digit_height, j:j+10] = small_bg\n",
    "            xmin = int((square_hw-digit_width)/2)\n",
    "            square[0:square_hw, xmin:xmin+digit_width] = digit\n",
    "\n",
    "            mask_xmin = int(xmin / square_hw * 255)\n",
    "            mask_ymin = int((padding_up_down/2) / square_hw * 255)\n",
    "            mask_width = int((xmin+digit_width) / square_hw * 255)\n",
    "            mask_height = int((square_hw-(padding_up_down//2)) / square_hw * 255)\n",
    "        \n",
    "        else:  # When the digit is wide and we have to extend the up and down part.\n",
    "            small_bg = digit[0:10, 0:digit_width]\n",
    "            for j in range(0, square_hw, 10):\n",
    "                if math.floor(square_hw/10)*10 == j:\n",
    "                    new_bg_height = square_hw%10 \n",
    "                    small_bg = digit[0:new_bg_height, 0:digit_width]\n",
    "                    square[j:j+new_bg_height, 0:digit_width] = small_bg\n",
    "                else:\n",
    "                    square[j:j+10, 0:digit_width] = small_bg\n",
    "            ymin = int((square_hw-digit_height)/2)\n",
    "            square[ymin:ymin+digit_height, 0:square_hw] = digit\n",
    "\n",
    "            mask_xmin = int((padding_sides//2) / square_hw * 255)\n",
    "            mask_ymin = int(ymin / square_hw * 255)\n",
    "            mask_width = int((square_hw-(padding_sides//2)) / square_hw * 255)\n",
    "            mask_height = int((ymin+digit_height) / square_hw * 255)\n",
    "\n",
    "        # Saving square image\n",
    "        output_image = Image.fromarray(np.uint8(square)).convert('RGB').resize((256,256))\n",
    "        image_path = osp.join(square_digits_path, \"{}/{}_{}.png\".format(i, frame_id, i))\n",
    "        output_image.save(image_path, format='png')\n",
    "\n",
    "        # Saving a mask\n",
    "        mask = np.zeros((256, 256), np.float32)\n",
    "        mask[mask_ymin:mask_height, mask_xmin:mask_width] = 1\n",
    "        mask_path = osp.join(square_digits_path, \"{}/{}_{}_mask.png\".format(i, frame_id, i))\n",
    "        mask = Image.fromarray(np.uint8(mask*255)).convert('L')\n",
    "        mask.save(mask_path, format='png')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6451dfd2-1298-4726-96b5-dbb8ad627117",
   "metadata": {},
   "source": [
    "### WavePaint image generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "713e686a-2dcc-4599-a4d9-808dceb7abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavepaint_predictions(square_digits_path, wavepaint_model, wavepaint_predict):\n",
    "\n",
    "    generated_img = osp.join(square_digits_path, \"generated\") \n",
    "    masked_img = osp.join(square_digits_path, \"masked\")\n",
    "\n",
    "    if not os.path.exists(generated_img):\n",
    "        os.makedirs(generated_img)\n",
    "\n",
    "    if not os.path.exists(masked_img):\n",
    "        os.makedirs(masked_img)\n",
    "\n",
    "    # Digit 1\n",
    "    !python {wavepaint_predict} -model_path {wavepaint_model} -test_data {osp.join(square_digits_path, \"0\")} -generated_img {generated_img} -masked_img {masked_img}\n",
    "\n",
    "    # Digit 2\n",
    "    !python {wavepaint_predict} -model_path {wavepaint_model} -test_data {osp.join(square_digits_path, \"1\")} -generated_img {generated_img} -masked_img {masked_img}\n",
    "\n",
    "    # Digit 3\n",
    "    !python {wavepaint_predict} -model_path {wavepaint_model} -test_data {osp.join(square_digits_path, \"2\")} -generated_img {generated_img} -masked_img {masked_img}\n",
    "\n",
    "    results_file_names = [f for f in os.listdir(generated_img) if f.endswith('.png')]\n",
    "    results_file_names.sort()\n",
    "\n",
    "    # Full paths for generated images\n",
    "    predictions = []\n",
    "    for i in range(len(results_file_names)):\n",
    "        if results_file_names[i][-4:] == '.png':\n",
    "            predictions.append(osp.join(generated_img, results_file_names[i]))\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98b2c032-b709-4b6a-b329-aab8f1be0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generating_new_digits(predictions, frame_labels, frame_width, frame_height, padding_up_down, padding_sides):\n",
    "\n",
    "    new_digits = []\n",
    "    for i in range(len(predictions)):\n",
    "\n",
    "        prediction = cv2.cvtColor(cv2.imread(predictions[i]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Here we have to find the digit sizes\n",
    "        org_digit_width = int(frame_labels[i][3] * frame_width + padding_sides)\n",
    "        org_digit_height = int(frame_labels[i][4] * frame_height + padding_up_down)\n",
    "\n",
    "        bigger_height = True if org_digit_width <= org_digit_height else False\n",
    "        if bigger_height:\n",
    "            image = cv2.resize(prediction, (org_digit_height, org_digit_height), interpolation=cv2.INTER_CUBIC)\n",
    "            side = int((org_digit_height - org_digit_width)/2)\n",
    "            digit = image[ : , side:side+org_digit_width]\n",
    "        else:\n",
    "            image = cv2.resize(prediction, (org_digit_width, org_digit_width), interpolation=cv2.INTER_CUBIC)\n",
    "            side = int((org_digit_width - org_digit_height)/2)\n",
    "            digit = image[side:side+org_digit_height , :]\n",
    "    \n",
    "        new_digits.append(digit)\n",
    "        i += 1\n",
    "    return new_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381583b-265a-414c-b17a-ee8a76823959",
   "metadata": {},
   "source": [
    "### Placing the new digits back into the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8605ae86-a93b-4559-85cf-d10143c27ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacing_digits_with_predictions(image_replaced, frame_labels, frame_width, frame_height, generated_digits, changed_frames_path, image_id, padding_up_down, padding_sides):\n",
    "    \n",
    "    for i in range(len(generated_digits)):\n",
    "        # Finding the position\n",
    "        digit_width = int(frame_labels[i][3] * frame_width + padding_sides) # Adding more pixels for a boundary\n",
    "        digit_height = int(frame_labels[i][4] * frame_height + padding_up_down )\n",
    "        xmin = int((frame_labels[i][1] * frame_width) - digit_width/2)\n",
    "        ymin = int((frame_labels[i][2] * frame_height) - digit_height/2)\n",
    "    \n",
    "        # Change digit\n",
    "        digit = (generated_digits[i]).astype('int')\n",
    "        rgba = np.dstack((digit, np.full(digit.shape[:-1], 255)))\n",
    "        digit = Image.fromarray(np.uint8(rgba)).convert('RGBA')\n",
    "    \n",
    "        # Placing digit onto frame\n",
    "        image_replaced.paste(digit, (xmin, ymin), digit)\n",
    "\n",
    "    file_path = osp.join(changed_frames_path, \"frame_{}_r.png\".format(image_id))\n",
    "    final_frame_resize = image_replaced.resize((1600, 900))\n",
    "    final_frame_resize.save(file_path, format='png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f540768-9b35-4fdb-98cc-336d2b35392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def changing_digits_in_the_frames(frames_path, bboxes_path, square_digits_path, changed_frames_path, id_length, padding_up_down, padding_sides, wavepaint_model, wavepaint_predict):\n",
    "\n",
    "    frames_files = [f for f in os.listdir(frames_path) if f.endswith('.png')]\n",
    "    frames_files.sort()\n",
    "    \n",
    "    bboxes_files = [f for f in os.listdir(bboxes_path) if f.endswith('.txt')]\n",
    "    bboxes_files.sort()\n",
    "\n",
    "    if not os.path.exists(changed_frames_path):\n",
    "        os.makedirs(changed_frames_path)\n",
    "\n",
    "    # Finding frame size\n",
    "    frame_1_path = osp.join(frames_path, frames_files[0])\n",
    "    frame_1 = cv2.cvtColor(cv2.imread(frame_1_path), cv2.COLOR_BGR2RGB)\n",
    "    frame_width = frame_1.shape[1]\n",
    "    frame_height = frame_1.shape[0]\n",
    "\n",
    "    \n",
    "    print(\"Creating square digits\")\n",
    "\n",
    "    for idx in tqdm(range(len(frames_files))):\n",
    "        \n",
    "        frame_path = osp.join(frames_path, frames_files[idx])\n",
    "        frame_np = cv2.cvtColor(cv2.imread(frame_path), cv2.COLOR_BGR2RGB)\n",
    "        label_path = osp.join(bboxes_path, bboxes_files[idx])\n",
    "        frame_labels = reading_in_bbox_txt_file(label_path)\n",
    "        image_id = '0' * (id_length - len(str(idx))) + str(idx)\n",
    "\n",
    "        # Getting the digit from frame\n",
    "        digits = finding_digits_from_the_frame(frame_np, frame_width, frame_height, frame_labels, padding_up_down, padding_sides)\n",
    "\n",
    "        if len(digits) != 0:\n",
    "\n",
    "            # Adding background to the digit\n",
    "            changing_digit_into_square(digits, square_digits_path, image_id, padding_up_down, padding_sides) # Saving all the squared digits\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"WavePaint making predictions\")\n",
    "    # Generating results\n",
    "    prediction_files = wavepaint_predictions(square_digits_path, wavepaint_model, wavepaint_predict)\n",
    "    prediction_files.sort()\n",
    "\n",
    "    prediction_idx = 0\n",
    "\n",
    "    print(\"Placing predictions into frames\")\n",
    "    # Placing results into a video\n",
    "\n",
    "    for idx in tqdm(range(len(frames_files))):\n",
    "       \n",
    "        frame_path = osp.join(frames_path, frames_files[idx])\n",
    "        frame_image = Image.open(frame_path).convert('RGBA')\n",
    "        label_path = osp.join(bboxes_path, bboxes_files[idx])\n",
    "        frame_labels = reading_in_bbox_txt_file(label_path)\n",
    "        image_id = '0' * (id_length - len(str(idx))) + str(idx)\n",
    "\n",
    "        # Is there a digit to change?\n",
    "        nr_of_digits = len(frame_labels)\n",
    "\n",
    "        if nr_of_digits != 0:\n",
    "            frame_digit_predictions = prediction_files[prediction_idx:prediction_idx+nr_of_digits]\n",
    "\n",
    "            # Formatting the new digits\n",
    "            generated_digits = generating_new_digits(frame_digit_predictions, frame_labels, frame_width, frame_height, padding_up_down, padding_sides)\n",
    "\n",
    "            # Placing digits into the frame and saving it\n",
    "            new_frame = replacing_digits_with_predictions(frame_image, frame_labels, frame_width, frame_height, generated_digits, changed_frames_path, image_id, padding_up_down, padding_sides)\n",
    "            \n",
    "            prediction_idx += nr_of_digits\n",
    "        else:\n",
    "            # Save the same frame\n",
    "            file_path = osp.join(changed_frames_path, \"frame_{}_r.png\".format(image_id))\n",
    "            final_frame_resize = frame_image.resize((1280, 720))\n",
    "            final_frame_resize.save(file_path, format='png')\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d3db2-ce14-4bf5-bd15-37407ac33f03",
   "metadata": {},
   "source": [
    "### Putting the video together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2452d6af-85cf-45eb-adbc-0f2f42223998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_video_from_frames(video_file, frames_folder, video_name):\n",
    "\n",
    "    fps = cv2.VideoCapture(video_file).get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    images = [img for img in os.listdir(frames_folder) if img.endswith(\".png\")]\n",
    "    images.sort(key=lambda x: (int(x.split(\"_\")[-2])))\n",
    "    frame = cv2.imread(os.path.join(frames_folder, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    video = cv2.VideoWriter(video_name, fourcc, fps, (width,height))\n",
    "    \n",
    "    for image in tqdm(images):\n",
    "        video.write(cv2.imread(os.path.join(frames_folder, image)))\n",
    "    video.release()\n",
    "\n",
    "\n",
    "def getting_video_audio(video_file, audio_file):\n",
    "    video_clip = VideoFileClip(video_file)  # Load the video clip\n",
    "    audio_clip = video_clip.audio # Extract the audio from the video clip\n",
    "    audio_clip.write_audiofile(audio_file)  # Write the audio to a separate file\n",
    "    audio_clip.close()\n",
    "    video_clip.close()\n",
    "\n",
    "\n",
    "def adding_audio_to_a_video(video_file, audio_file, video_output):\n",
    "    audio = AudioFileClip(audio_file)\n",
    "    video = VideoFileClip(video_file)\n",
    "    video.audio = audio\n",
    "    video.write_videofile(video_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "126f1e98-673e-4d20-9d8c-9142c7ad506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_files(video_changed_fps_path, video_frames, audio_file, frames_path, yolo_boxes_path, bboxes_path, square_digits_path, changed_frames_path, tracked_labels_path):\n",
    "    \n",
    "    # Remove everything except the final video\n",
    "    os.remove(video_frames)\n",
    "    os.remove(audio_file)\n",
    "    os.remove(video_changed_fps_path)\n",
    "    shutil.rmtree(frames_path, ignore_errors=True)\n",
    "    shutil.rmtree(yolo_boxes_path, ignore_errors=True)\n",
    "    shutil.rmtree(bboxes_path, ignore_errors=True)\n",
    "    shutil.rmtree(square_digits_path, ignore_errors=True)\n",
    "    shutil.rmtree(changed_frames_path, ignore_errors=True)\n",
    "    shutil.rmtree(tracked_labels_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f79010-0855-412f-b26d-df447c7b500e",
   "metadata": {},
   "source": [
    "# Start of the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a21c5f60-4472-4292-b2bd-8a88d3600e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "video = \"../datasets/voting_ballots_data/videos_filled/videos/per_17_vid_5_filled.mp4\" # original video\n",
    "corner_file_path = \"../datasets/voting_ballots_data/videos_filled/corners/per_17_vid_5_filled.txt\" # first frame corner coordinates\n",
    "save_path = \"pipeline_results\"\n",
    "description = \"p17_v5_covered_test\"\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "video_changed_fps_path = \"{}/{}_changed_fps.mp4\".format(save_path, description) # video frames\n",
    "frames_path = \"{}/{}_frames\".format(save_path, description) # video frames\n",
    "tracked_labels_path = \"{}/{}_track_labels\".format(save_path, description) # video frames\n",
    "yolo_boxes_path = \"{}/{}_yolo\".format(save_path, description)\n",
    "bboxes_path = \"{}/{}_labels\".format(save_path, description)\n",
    "square_digits_path = \"{}/{}_square\".format(save_path, description) # bounding boxes\n",
    "changed_frames_path = \"{}/{}_frames_changed\".format(save_path, description) # video frames\n",
    "audio = \"{}/{}_audio.mp3\".format(save_path, description) # audio file\n",
    "video_frames = \"{}/{}_labels.mp4\".format(save_path, description) # video without audio\n",
    "video_final = \"{}/{}.mp4\".format(save_path, description) # video with audio\n",
    "\n",
    "YOLO_model = YOLO(\"../training_YOLO/YOLO11m_e15_img1920_oneClass.pt\")\n",
    "wavepaint_model_file = \"../training_WavePaint/WavePaint_blocks4_dim128_modules6_trained_model.pth\"\n",
    "wavepaint_predict = \"../training_WavePaint/predict.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c333a5d7-7a2a-450e-9642-e32eb8f11999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "frame_index:   0%|                  | 2/618 [00:59<5:05:22, 29.74s/it, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change the fps of the video\n",
      "{'video_found': True, 'audio_found': True, 'metadata': {'major_brand': 'isom', 'minor_version': '512', 'compatible_brands': 'isomiso2avc1mp41', 'encoder': 'Lavf61.1.100'}, 'inputs': [{'streams': [{'input_number': 0, 'stream_number': 0, 'stream_type': 'video', 'language': None, 'default': True, 'size': [1920, 1080], 'bitrate': 2827, 'fps': 29.97002997002997, 'codec_name': 'h264', 'profile': '(High)', 'metadata': {'Metadata': '', 'handler_name': 'VideoHandler', 'vendor_id': '[0][0][0][0]', 'encoder': 'Lavc61.3.100 libx264'}}, {'input_number': 0, 'stream_number': 1, 'stream_type': 'audio', 'language': None, 'default': True, 'fps': 44100, 'bitrate': 127, 'metadata': {'Metadata': '', 'handler_name': 'SoundHandler', 'vendor_id': '[0][0][0][0]'}}], 'input_number': 0}], 'duration': 25.78, 'bitrate': 2960, 'start': 0.0, 'default_video_input_number': 0, 'default_video_stream_number': 0, 'video_codec_name': 'h264', 'video_profile': '(High)', 'video_size': [1920, 1080], 'video_bitrate': 2827, 'video_fps': 29.97002997002997, 'default_audio_input_number': 0, 'default_audio_stream_number': 1, 'audio_fps': 44100, 'audio_bitrate': 127, 'video_duration': 25.78, 'video_n_frames': 772}\n",
      "/home/ahabanen/virEnvs/pipeline/lib/python3.11/site-packages/imageio_ffmpeg/binaries/ffmpeg-linux-x86_64-v7.0.2 -i ../datasets/voting_ballots_data/videos_filled/videos/per_17_vid_5_filled.mp4 -loglevel error -f image2pipe -vf scale=1920:1080 -sws_flags bicubic -pix_fmt rgb24 -vcodec rawvideo -\n",
      "MoviePy - Building video pipeline_results/p17_v5_covered_test_changed_fps.mp4.\n",
      "MoviePy - Writing audio in p17_v5_covered_test_changed_fpsTEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "chunk:   0%|                                  | 0/569 [00:00<?, ?it/s, now=None]\u001b[A\n",
      "chunk:  27%|█████▉                | 153/569 [00:00<00:00, 1488.29it/s, now=None]\u001b[A\n",
      "chunk:  68%|██████████████▉       | 385/569 [00:00<00:00, 1968.92it/s, now=None]\u001b[A\n",
      "frame_index:   0%|                  | 2/618 [00:59<5:07:00, 29.90s/it, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing video pipeline_results/p17_v5_covered_test_changed_fps.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "frame_index:   0%|                            | 0/618 [00:00<?, ?it/s, now=None]\u001b[A\n",
      "frame_index:   2%|▎                 | 12/618 [00:00<00:05, 116.65it/s, now=None]\u001b[A\n",
      "frame_index:   4%|▋                 | 24/618 [00:00<00:05, 109.52it/s, now=None]\u001b[A\n",
      "frame_index:   6%|█                 | 35/618 [00:00<00:05, 107.75it/s, now=None]\u001b[A\n",
      "frame_index:   7%|█▎                | 46/618 [00:00<00:05, 102.39it/s, now=None]\u001b[A\n",
      "frame_index:   9%|█▊                 | 57/618 [00:00<00:05, 95.76it/s, now=None]\u001b[A\n",
      "frame_index:  11%|██                 | 67/618 [00:00<00:06, 89.90it/s, now=None]\u001b[A\n",
      "frame_index:  12%|██▎                | 77/618 [00:00<00:06, 85.89it/s, now=None]\u001b[A\n",
      "frame_index:  14%|██▋                | 86/618 [00:00<00:06, 76.28it/s, now=None]\u001b[A\n",
      "frame_index:  15%|██▉                | 94/618 [00:01<00:06, 75.30it/s, now=None]\u001b[A\n",
      "frame_index:  17%|██▉               | 102/618 [00:01<00:07, 73.04it/s, now=None]\u001b[A\n",
      "frame_index:  18%|███▏              | 111/618 [00:01<00:06, 77.05it/s, now=None]\u001b[A\n",
      "frame_index:  20%|███▌              | 123/618 [00:01<00:05, 86.06it/s, now=None]\u001b[A\n",
      "frame_index:  22%|███▊              | 133/618 [00:01<00:05, 88.98it/s, now=None]\u001b[A\n",
      "frame_index:  23%|████▏             | 143/618 [00:01<00:05, 88.96it/s, now=None]\u001b[A\n",
      "frame_index:  25%|████▍             | 152/618 [00:01<00:05, 86.67it/s, now=None]\u001b[A\n",
      "frame_index:  26%|████▋             | 162/618 [00:01<00:05, 88.52it/s, now=None]\u001b[A\n",
      "frame_index:  28%|████▉             | 171/618 [00:01<00:05, 85.40it/s, now=None]\u001b[A\n",
      "frame_index:  29%|█████▏            | 180/618 [00:02<00:05, 85.64it/s, now=None]\u001b[A\n",
      "frame_index:  31%|█████▌            | 191/618 [00:02<00:04, 92.11it/s, now=None]\u001b[A\n",
      "frame_index:  33%|█████▊            | 201/618 [00:02<00:04, 91.95it/s, now=None]\u001b[A\n",
      "frame_index:  34%|██████▏           | 211/618 [00:02<00:04, 93.49it/s, now=None]\u001b[A\n",
      "frame_index:  36%|██████▍           | 221/618 [00:02<00:04, 94.16it/s, now=None]\u001b[A\n",
      "frame_index:  37%|██████▋           | 231/618 [00:02<00:04, 95.29it/s, now=None]\u001b[A\n",
      "frame_index:  39%|███████           | 241/618 [00:02<00:03, 95.24it/s, now=None]\u001b[A\n",
      "frame_index:  41%|███████▎          | 251/618 [00:02<00:03, 95.27it/s, now=None]\u001b[A\n",
      "frame_index:  42%|███████▌          | 261/618 [00:02<00:03, 93.47it/s, now=None]\u001b[A\n",
      "frame_index:  44%|███████▉          | 271/618 [00:03<00:03, 92.01it/s, now=None]\u001b[A\n",
      "frame_index:  45%|████████▏         | 281/618 [00:03<00:03, 90.94it/s, now=None]\u001b[A\n",
      "frame_index:  47%|████████▍         | 291/618 [00:03<00:03, 93.05it/s, now=None]\u001b[A\n",
      "frame_index:  49%|████████▊         | 301/618 [00:03<00:03, 93.50it/s, now=None]\u001b[A\n",
      "frame_index:  50%|█████████         | 311/618 [00:03<00:03, 86.26it/s, now=None]\u001b[A\n",
      "frame_index:  52%|█████████▎        | 320/618 [00:03<00:03, 83.60it/s, now=None]\u001b[A\n",
      "frame_index:  53%|█████████▌        | 329/618 [00:03<00:03, 84.84it/s, now=None]\u001b[A\n",
      "frame_index:  55%|█████████▊        | 338/618 [00:03<00:03, 85.48it/s, now=None]\u001b[A\n",
      "frame_index:  56%|██████████▏       | 348/618 [00:03<00:03, 87.65it/s, now=None]\u001b[A\n",
      "frame_index:  58%|██████████▍       | 357/618 [00:04<00:02, 88.24it/s, now=None]\u001b[A\n",
      "frame_index:  59%|██████████▋       | 366/618 [00:04<00:02, 88.65it/s, now=None]\u001b[A\n",
      "frame_index:  61%|███████████       | 378/618 [00:04<00:02, 96.88it/s, now=None]\u001b[A\n",
      "frame_index:  63%|███████████▎      | 389/618 [00:04<00:02, 98.69it/s, now=None]\u001b[A\n",
      "frame_index:  65%|███████████▌      | 399/618 [00:04<00:02, 98.41it/s, now=None]\u001b[A\n",
      "frame_index:  66%|███████████▉      | 409/618 [00:04<00:02, 96.86it/s, now=None]\u001b[A\n",
      "frame_index:  68%|████████████▏     | 420/618 [00:04<00:02, 98.35it/s, now=None]\u001b[A\n",
      "frame_index:  70%|████████████▌     | 430/618 [00:04<00:02, 91.92it/s, now=None]\u001b[A\n",
      "frame_index:  72%|████████████▊     | 442/618 [00:04<00:01, 98.06it/s, now=None]\u001b[A\n",
      "frame_index:  74%|████████████▌    | 457/618 [00:04<00:01, 110.33it/s, now=None]\u001b[A\n",
      "frame_index:  76%|████████████▉    | 469/618 [00:05<00:01, 109.33it/s, now=None]\u001b[A\n",
      "frame_index:  78%|█████████████▏   | 480/618 [00:05<00:01, 107.13it/s, now=None]\u001b[A\n",
      "frame_index:  79%|█████████████▌   | 491/618 [00:05<00:01, 101.40it/s, now=None]\u001b[A\n",
      "frame_index:  81%|██████████████▌   | 502/618 [00:05<00:01, 95.18it/s, now=None]\u001b[A\n",
      "frame_index:  83%|██████████████▉   | 512/618 [00:05<00:01, 92.91it/s, now=None]\u001b[A\n",
      "frame_index:  84%|███████████████▏  | 522/618 [00:05<00:01, 90.71it/s, now=None]\u001b[A\n",
      "frame_index:  86%|███████████████▍  | 532/618 [00:05<00:01, 85.93it/s, now=None]\u001b[A\n",
      "frame_index:  88%|███████████████▊  | 541/618 [00:05<00:00, 85.38it/s, now=None]\u001b[A\n",
      "frame_index:  89%|████████████████  | 551/618 [00:06<00:00, 87.63it/s, now=None]\u001b[A\n",
      "frame_index:  91%|████████████████▎ | 562/618 [00:06<00:00, 92.36it/s, now=None]\u001b[A\n",
      "frame_index:  93%|████████████████▋ | 573/618 [00:06<00:00, 94.66it/s, now=None]\u001b[A\n",
      "frame_index:  94%|████████████████▉ | 583/618 [00:06<00:00, 95.85it/s, now=None]\u001b[A\n",
      "frame_index:  96%|█████████████████▎| 594/618 [00:06<00:00, 98.71it/s, now=None]\u001b[A\n",
      "frame_index:  98%|████████████████▋| 606/618 [00:06<00:00, 103.90it/s, now=None]\u001b[A\n",
      "frame_index: 100%|████████████████▉| 617/618 [00:06<00:00, 101.62it/s, now=None]\u001b[A\n",
      "frame_index:   0%|                  | 2/618 [01:06<5:43:35, 33.47s/it, now=None]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done !\n",
      "MoviePy - video ready pipeline_results/p17_v5_covered_test_changed_fps.mp4\n",
      "Saving video as frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  7.05it/s]\u001b[A\n",
      "4it [00:00, 18.40it/s]\u001b[A\n",
      "7it [00:00, 22.48it/s]\u001b[A\n",
      "10it [00:00, 24.27it/s]\u001b[A\n",
      "13it [00:00, 25.04it/s]\u001b[A\n",
      "16it [00:00, 25.29it/s]\u001b[A\n",
      "19it [00:00, 25.31it/s]\u001b[A\n",
      "22it [00:00, 25.36it/s]\u001b[A\n",
      "25it [00:01, 25.38it/s]\u001b[A\n",
      "28it [00:01, 25.27it/s]\u001b[A\n",
      "31it [00:01, 25.12it/s]\u001b[A\n",
      "34it [00:01, 24.82it/s]\u001b[A\n",
      "37it [00:01, 24.74it/s]\u001b[A\n",
      "40it [00:01, 24.63it/s]\u001b[A\n",
      "43it [00:01, 24.46it/s]\u001b[A\n",
      "46it [00:01, 24.43it/s]\u001b[A\n",
      "49it [00:02, 24.44it/s]\u001b[A\n",
      "52it [00:02, 24.44it/s]\u001b[A\n",
      "55it [00:02, 24.40it/s]\u001b[A\n",
      "58it [00:02, 24.33it/s]\u001b[A\n",
      "61it [00:02, 24.32it/s]\u001b[A\n",
      "64it [00:02, 24.34it/s]\u001b[A\n",
      "67it [00:02, 24.26it/s]\u001b[A\n",
      "70it [00:02, 24.20it/s]\u001b[A\n",
      "73it [00:03, 24.03it/s]\u001b[A\n",
      "76it [00:03, 23.88it/s]\u001b[A\n",
      "79it [00:03, 23.71it/s]\u001b[A\n",
      "82it [00:03, 23.81it/s]\u001b[A\n",
      "85it [00:03, 23.93it/s]\u001b[A\n",
      "88it [00:03, 24.15it/s]\u001b[A\n",
      "91it [00:03, 24.34it/s]\u001b[A\n",
      "94it [00:03, 24.45it/s]\u001b[A\n",
      "97it [00:04, 24.52it/s]\u001b[A\n",
      "100it [00:04, 24.52it/s]\u001b[A\n",
      "103it [00:04, 24.57it/s]\u001b[A\n",
      "106it [00:04, 24.64it/s]\u001b[A\n",
      "109it [00:04, 24.73it/s]\u001b[A\n",
      "112it [00:04, 24.84it/s]\u001b[A\n",
      "115it [00:04, 24.90it/s]\u001b[A\n",
      "118it [00:04, 24.97it/s]\u001b[A\n",
      "121it [00:04, 24.99it/s]\u001b[A\n",
      "124it [00:05, 25.04it/s]\u001b[A\n",
      "127it [00:05, 25.10it/s]\u001b[A\n",
      "130it [00:05, 25.05it/s]\u001b[A\n",
      "133it [00:05, 24.99it/s]\u001b[A\n",
      "136it [00:05, 24.91it/s]\u001b[A\n",
      "139it [00:05, 24.87it/s]\u001b[A\n",
      "142it [00:05, 24.87it/s]\u001b[A\n",
      "145it [00:05, 24.70it/s]\u001b[A\n",
      "148it [00:06, 24.69it/s]\u001b[A\n",
      "151it [00:06, 24.70it/s]\u001b[A\n",
      "154it [00:06, 24.74it/s]\u001b[A\n",
      "157it [00:06, 24.70it/s]\u001b[A\n",
      "160it [00:06, 24.64it/s]\u001b[A\n",
      "163it [00:06, 24.62it/s]\u001b[A\n",
      "166it [00:06, 24.67it/s]\u001b[A\n",
      "169it [00:06, 24.70it/s]\u001b[A\n",
      "172it [00:07, 24.54it/s]\u001b[A\n",
      "175it [00:07, 24.47it/s]\u001b[A\n",
      "178it [00:07, 24.46it/s]\u001b[A\n",
      "181it [00:07, 24.53it/s]\u001b[A\n",
      "184it [00:07, 24.53it/s]\u001b[A\n",
      "187it [00:07, 24.56it/s]\u001b[A\n",
      "190it [00:07, 24.52it/s]\u001b[A\n",
      "193it [00:07, 24.55it/s]\u001b[A\n",
      "196it [00:08, 24.59it/s]\u001b[A\n",
      "199it [00:08, 24.59it/s]\u001b[A\n",
      "202it [00:08, 24.64it/s]\u001b[A\n",
      "205it [00:08, 24.71it/s]\u001b[A\n",
      "208it [00:08, 24.74it/s]\u001b[A\n",
      "211it [00:08, 24.66it/s]\u001b[A\n",
      "214it [00:08, 24.50it/s]\u001b[A\n",
      "217it [00:08, 24.54it/s]\u001b[A\n",
      "220it [00:08, 24.67it/s]\u001b[A\n",
      "223it [00:09, 24.82it/s]\u001b[A\n",
      "226it [00:09, 24.92it/s]\u001b[A\n",
      "229it [00:09, 25.14it/s]\u001b[A\n",
      "232it [00:09, 25.19it/s]\u001b[A\n",
      "235it [00:09, 25.20it/s]\u001b[A\n",
      "238it [00:09, 25.09it/s]\u001b[A\n",
      "241it [00:09, 25.00it/s]\u001b[A\n",
      "244it [00:09, 24.87it/s]\u001b[A\n",
      "247it [00:10, 24.79it/s]\u001b[A\n",
      "250it [00:10, 24.71it/s]\u001b[A\n",
      "253it [00:10, 25.52it/s]\u001b[A\n",
      "256it [00:10, 25.82it/s]\u001b[A\n",
      "259it [00:10, 25.85it/s]\u001b[A\n",
      "262it [00:10, 25.59it/s]\u001b[A\n",
      "265it [00:10, 25.50it/s]\u001b[A\n",
      "268it [00:10, 25.42it/s]\u001b[A\n",
      "271it [00:11, 25.07it/s]\u001b[A\n",
      "274it [00:11, 24.73it/s]\u001b[A\n",
      "277it [00:11, 24.50it/s]\u001b[A\n",
      "280it [00:11, 24.37it/s]\u001b[A\n",
      "283it [00:11, 24.37it/s]\u001b[A\n",
      "286it [00:11, 24.39it/s]\u001b[A\n",
      "289it [00:11, 24.53it/s]\u001b[A\n",
      "292it [00:11, 24.67it/s]\u001b[A\n",
      "295it [00:11, 25.26it/s]\u001b[A\n",
      "298it [00:12, 26.44it/s]\u001b[A\n",
      "301it [00:12, 27.17it/s]\u001b[A\n",
      "304it [00:12, 27.51it/s]\u001b[A\n",
      "307it [00:12, 27.56it/s]\u001b[A\n",
      "310it [00:12, 27.31it/s]\u001b[A\n",
      "313it [00:12, 27.08it/s]\u001b[A\n",
      "316it [00:12, 26.82it/s]\u001b[A\n",
      "319it [00:12, 26.61it/s]\u001b[A\n",
      "322it [00:12, 26.33it/s]\u001b[A\n",
      "325it [00:13, 25.97it/s]\u001b[A\n",
      "328it [00:13, 25.61it/s]\u001b[A\n",
      "331it [00:13, 25.34it/s]\u001b[A\n",
      "334it [00:13, 25.12it/s]\u001b[A\n",
      "337it [00:13, 25.37it/s]\u001b[A\n",
      "340it [00:13, 26.33it/s]\u001b[A\n",
      "344it [00:13, 27.72it/s]\u001b[A\n",
      "347it [00:13, 28.21it/s]\u001b[A\n",
      "350it [00:14, 28.67it/s]\u001b[A\n",
      "353it [00:14, 28.99it/s]\u001b[A\n",
      "357it [00:14, 29.42it/s]\u001b[A\n",
      "361it [00:14, 30.06it/s]\u001b[A\n",
      "365it [00:14, 30.10it/s]\u001b[A\n",
      "369it [00:14, 30.05it/s]\u001b[A\n",
      "373it [00:14, 29.93it/s]\u001b[A\n",
      "376it [00:14, 29.79it/s]\u001b[A\n",
      "379it [00:14, 29.49it/s]\u001b[A\n",
      "382it [00:15, 29.26it/s]\u001b[A\n",
      "385it [00:15, 29.09it/s]\u001b[A\n",
      "388it [00:15, 28.91it/s]\u001b[A\n",
      "391it [00:15, 29.00it/s]\u001b[A\n",
      "394it [00:15, 29.27it/s]\u001b[A\n",
      "398it [00:15, 30.10it/s]\u001b[A\n",
      "402it [00:15, 31.05it/s]\u001b[A\n",
      "406it [00:15, 31.41it/s]\u001b[A\n",
      "410it [00:15, 31.35it/s]\u001b[A\n",
      "414it [00:16, 31.69it/s]\u001b[A\n",
      "418it [00:16, 30.97it/s]\u001b[A\n",
      "422it [00:16, 30.84it/s]\u001b[A\n",
      "426it [00:16, 30.05it/s]\u001b[A\n",
      "430it [00:16, 28.85it/s]\u001b[A\n",
      "433it [00:16, 27.99it/s]\u001b[A\n",
      "436it [00:16, 27.22it/s]\u001b[A\n",
      "439it [00:17, 26.71it/s]\u001b[A\n",
      "442it [00:17, 26.00it/s]\u001b[A\n",
      "445it [00:17, 25.39it/s]\u001b[A\n",
      "448it [00:17, 24.79it/s]\u001b[A\n",
      "451it [00:17, 24.37it/s]\u001b[A\n",
      "454it [00:17, 24.00it/s]\u001b[A\n",
      "457it [00:17, 23.72it/s]\u001b[A\n",
      "460it [00:17, 23.41it/s]\u001b[A\n",
      "463it [00:18, 23.11it/s]\u001b[A\n",
      "466it [00:18, 22.42it/s]\u001b[A\n",
      "469it [00:18, 22.43it/s]\u001b[A\n",
      "472it [00:18, 22.47it/s]\u001b[A\n",
      "475it [00:18, 22.49it/s]\u001b[A\n",
      "478it [00:18, 22.62it/s]\u001b[A\n",
      "481it [00:18, 22.71it/s]\u001b[A\n",
      "484it [00:18, 22.84it/s]\u001b[A\n",
      "487it [00:19, 23.01it/s]\u001b[A\n",
      "490it [00:19, 23.13it/s]\u001b[A\n",
      "493it [00:19, 23.19it/s]\u001b[A\n",
      "496it [00:19, 23.14it/s]\u001b[A\n",
      "499it [00:19, 23.49it/s]\u001b[A\n",
      "502it [00:19, 24.54it/s]\u001b[A\n",
      "505it [00:19, 25.81it/s]\u001b[A\n",
      "509it [00:19, 27.43it/s]\u001b[A\n",
      "513it [00:20, 28.56it/s]\u001b[A\n",
      "516it [00:20, 28.46it/s]\u001b[A\n",
      "519it [00:20, 27.76it/s]\u001b[A\n",
      "522it [00:20, 26.92it/s]\u001b[A\n",
      "525it [00:20, 26.03it/s]\u001b[A\n",
      "528it [00:20, 25.25it/s]\u001b[A\n",
      "531it [00:20, 24.60it/s]\u001b[A\n",
      "534it [00:20, 23.95it/s]\u001b[A\n",
      "537it [00:21, 23.30it/s]\u001b[A\n",
      "540it [00:21, 22.67it/s]\u001b[A\n",
      "543it [00:21, 21.91it/s]\u001b[A\n",
      "546it [00:21, 21.69it/s]\u001b[A\n",
      "549it [00:21, 21.54it/s]\u001b[A\n",
      "552it [00:21, 21.43it/s]\u001b[A\n",
      "555it [00:21, 21.36it/s]\u001b[A\n",
      "558it [00:22, 21.29it/s]\u001b[A\n",
      "561it [00:22, 21.26it/s]\u001b[A\n",
      "564it [00:22, 21.32it/s]\u001b[A\n",
      "567it [00:22, 21.39it/s]\u001b[A\n",
      "570it [00:22, 21.44it/s]\u001b[A\n",
      "573it [00:22, 21.35it/s]\u001b[A\n",
      "576it [00:22, 21.12it/s]\u001b[A\n",
      "579it [00:23, 21.04it/s]\u001b[A\n",
      "582it [00:23, 21.04it/s]\u001b[A\n",
      "585it [00:23, 21.02it/s]\u001b[A\n",
      "588it [00:23, 20.97it/s]\u001b[A\n",
      "591it [00:23, 20.89it/s]\u001b[A\n",
      "594it [00:23, 20.77it/s]\u001b[A\n",
      "597it [00:23, 20.66it/s]\u001b[A\n",
      "600it [00:24, 20.56it/s]\u001b[A\n",
      "603it [00:24, 20.65it/s]\u001b[A\n",
      "606it [00:24, 21.08it/s]\u001b[A\n",
      "609it [00:24, 21.39it/s]\u001b[A\n",
      "612it [00:24, 21.56it/s]\u001b[A\n",
      "615it [00:24, 21.67it/s]\u001b[A\n",
      "618it [00:24, 24.80it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding corners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                   | 0/617 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|▎                                          | 5/617 [00:00<00:14, 41.81it/s]\u001b[A\n",
      "  2%|▋                                         | 10/617 [00:00<00:14, 41.24it/s]\u001b[A\n",
      "  2%|█                                         | 15/617 [00:00<00:14, 41.22it/s]\u001b[A\n",
      "  3%|█▎                                        | 20/617 [00:00<00:14, 41.13it/s]\u001b[A\n",
      "  4%|█▋                                        | 25/617 [00:00<00:14, 40.83it/s]\u001b[A\n",
      "  5%|██                                        | 30/617 [00:00<00:14, 40.51it/s]\u001b[A\n",
      "  6%|██▍                                       | 35/617 [00:00<00:14, 40.17it/s]\u001b[A\n",
      "  6%|██▋                                       | 40/617 [00:00<00:14, 39.89it/s]\u001b[A\n",
      "  7%|██▉                                       | 44/617 [00:01<00:14, 39.65it/s]\u001b[A\n",
      "  8%|███▎                                      | 48/617 [00:01<00:14, 39.53it/s]\u001b[A\n",
      "  8%|███▌                                      | 52/617 [00:01<00:14, 39.48it/s]\u001b[A\n",
      "  9%|███▊                                      | 56/617 [00:01<00:14, 39.42it/s]\u001b[A\n",
      " 10%|████                                      | 60/617 [00:01<00:14, 39.42it/s]\u001b[A\n",
      " 10%|████▎                                     | 64/617 [00:01<00:14, 39.40it/s]\u001b[A\n",
      " 11%|████▋                                     | 68/617 [00:01<00:13, 39.30it/s]\u001b[A\n",
      " 12%|████▉                                     | 72/617 [00:01<00:13, 39.10it/s]\u001b[A\n",
      " 12%|█████▏                                    | 76/617 [00:01<00:13, 39.09it/s]\u001b[A\n",
      " 13%|█████▍                                    | 80/617 [00:02<00:13, 39.00it/s]\u001b[A\n",
      " 14%|█████▋                                    | 84/617 [00:02<00:13, 38.70it/s]\u001b[A\n",
      " 14%|█████▉                                    | 88/617 [00:02<00:13, 38.86it/s]\u001b[A\n",
      " 15%|██████▎                                   | 92/617 [00:02<00:13, 39.02it/s]\u001b[A\n",
      " 16%|██████▌                                   | 96/617 [00:02<00:13, 39.14it/s]\u001b[A\n",
      " 16%|██████▋                                  | 100/617 [00:02<00:13, 39.19it/s]\u001b[A\n",
      " 17%|██████▉                                  | 104/617 [00:02<00:13, 39.25it/s]\u001b[A\n",
      " 18%|███████▏                                 | 108/617 [00:02<00:12, 39.37it/s]\u001b[A\n",
      " 18%|███████▍                                 | 112/617 [00:02<00:12, 39.46it/s]\u001b[A\n",
      " 19%|███████▋                                 | 116/617 [00:02<00:12, 39.56it/s]\u001b[A\n",
      " 19%|███████▉                                 | 120/617 [00:03<00:12, 39.64it/s]\u001b[A\n",
      " 20%|████████▎                                | 125/617 [00:03<00:12, 39.85it/s]\u001b[A\n",
      " 21%|████████▌                                | 129/617 [00:03<00:12, 39.87it/s]\u001b[A\n",
      " 22%|████████▊                                | 133/617 [00:03<00:12, 39.80it/s]\u001b[A\n",
      " 22%|█████████                                | 137/617 [00:03<00:12, 39.75it/s]\u001b[A\n",
      " 23%|█████████▎                               | 141/617 [00:03<00:11, 39.70it/s]\u001b[A\n",
      " 24%|█████████▋                               | 145/617 [00:03<00:11, 39.68it/s]\u001b[A\n",
      " 24%|█████████▉                               | 150/617 [00:03<00:11, 39.87it/s]\u001b[A\n",
      " 25%|██████████▎                              | 155/617 [00:03<00:11, 40.02it/s]\u001b[A\n",
      " 26%|██████████▌                              | 159/617 [00:04<00:11, 39.87it/s]\u001b[A\n",
      " 26%|██████████▊                              | 163/617 [00:04<00:11, 39.80it/s]\u001b[A\n",
      " 27%|███████████                              | 167/617 [00:04<00:11, 39.72it/s]\u001b[A\n",
      " 28%|███████████▎                             | 171/617 [00:04<00:11, 39.49it/s]\u001b[A\n",
      " 28%|███████████▋                             | 175/617 [00:04<00:11, 39.26it/s]\u001b[A\n",
      " 29%|███████████▉                             | 179/617 [00:04<00:11, 39.33it/s]\u001b[A\n",
      " 30%|████████████▏                            | 183/617 [00:04<00:11, 39.36it/s]\u001b[A\n",
      " 30%|████████████▍                            | 187/617 [00:04<00:10, 39.37it/s]\u001b[A\n",
      " 31%|████████████▋                            | 191/617 [00:04<00:10, 39.37it/s]\u001b[A\n",
      " 32%|████████████▉                            | 195/617 [00:04<00:10, 39.38it/s]\u001b[A\n",
      " 32%|█████████████▏                           | 199/617 [00:05<00:10, 39.34it/s]\u001b[A\n",
      " 33%|█████████████▍                           | 203/617 [00:05<00:10, 39.47it/s]\u001b[A\n",
      " 34%|█████████████▊                           | 207/617 [00:05<00:10, 39.49it/s]\u001b[A\n",
      " 34%|██████████████                           | 211/617 [00:05<00:10, 39.42it/s]\u001b[A\n",
      " 35%|██████████████▎                          | 215/617 [00:05<00:10, 39.42it/s]\u001b[A\n",
      " 35%|██████████████▌                          | 219/617 [00:05<00:10, 39.50it/s]\u001b[A\n",
      " 36%|██████████████▊                          | 223/617 [00:05<00:09, 39.59it/s]\u001b[A\n",
      " 37%|███████████████▏                         | 228/617 [00:05<00:09, 39.88it/s]\u001b[A\n",
      " 38%|███████████████▍                         | 233/617 [00:05<00:09, 39.98it/s]\u001b[A\n",
      " 38%|███████████████▋                         | 237/617 [00:05<00:09, 39.79it/s]\u001b[A\n",
      " 39%|████████████████                         | 241/617 [00:06<00:09, 39.54it/s]\u001b[A\n",
      " 40%|████████████████▎                        | 245/617 [00:06<00:09, 39.51it/s]\u001b[A\n",
      " 40%|████████████████▌                        | 249/617 [00:06<00:09, 39.43it/s]\u001b[A\n",
      " 41%|████████████████▉                        | 254/617 [00:06<00:09, 40.19it/s]\u001b[A\n",
      " 42%|█████████████████▏                       | 259/617 [00:06<00:08, 40.22it/s]\u001b[A\n",
      " 43%|█████████████████▌                       | 264/617 [00:06<00:08, 40.08it/s]\u001b[A\n",
      " 44%|█████████████████▉                       | 269/617 [00:06<00:08, 40.02it/s]\u001b[A\n",
      " 44%|██████████████████▏                      | 274/617 [00:06<00:08, 39.85it/s]\u001b[A\n",
      " 45%|██████████████████▍                      | 278/617 [00:07<00:08, 39.62it/s]\u001b[A\n",
      " 46%|██████████████████▋                      | 282/617 [00:07<00:08, 39.55it/s]\u001b[A\n",
      " 46%|███████████████████                      | 286/617 [00:07<00:08, 39.50it/s]\u001b[A\n",
      " 47%|███████████████████▎                     | 290/617 [00:07<00:08, 39.50it/s]\u001b[A\n",
      " 48%|███████████████████▌                     | 295/617 [00:07<00:08, 40.13it/s]\u001b[A\n",
      " 49%|███████████████████▉                     | 300/617 [00:07<00:07, 41.09it/s]\u001b[A\n",
      " 49%|████████████████████▎                    | 305/617 [00:07<00:07, 41.42it/s]\u001b[A\n",
      " 50%|████████████████████▌                    | 310/617 [00:07<00:07, 41.54it/s]\u001b[A\n",
      " 51%|████████████████████▉                    | 315/617 [00:07<00:07, 41.32it/s]\u001b[A\n",
      " 52%|█████████████████████▎                   | 320/617 [00:08<00:07, 41.11it/s]\u001b[A\n",
      " 53%|█████████████████████▌                   | 325/617 [00:08<00:07, 40.52it/s]\u001b[A\n",
      " 53%|█████████████████████▉                   | 330/617 [00:08<00:07, 39.81it/s]\u001b[A\n",
      " 54%|██████████████████████▏                  | 334/617 [00:08<00:07, 39.72it/s]\u001b[A\n",
      " 55%|██████████████████████▌                  | 339/617 [00:08<00:06, 40.14it/s]\u001b[A\n",
      " 56%|██████████████████████▊                  | 344/617 [00:08<00:06, 41.05it/s]\u001b[A\n",
      " 57%|███████████████████████▏                 | 349/617 [00:08<00:06, 41.58it/s]\u001b[A\n",
      " 57%|███████████████████████▌                 | 354/617 [00:08<00:06, 41.94it/s]\u001b[A\n",
      " 58%|███████████████████████▊                 | 359/617 [00:08<00:06, 42.37it/s]\u001b[A\n",
      " 59%|████████████████████████▏                | 364/617 [00:09<00:05, 42.67it/s]\u001b[A\n",
      " 60%|████████████████████████▌                | 369/617 [00:09<00:05, 42.83it/s]\u001b[A\n",
      " 61%|████████████████████████▊                | 374/617 [00:09<00:05, 42.89it/s]\u001b[A\n",
      " 61%|█████████████████████████▏               | 379/617 [00:09<00:05, 42.83it/s]\u001b[A\n",
      " 62%|█████████████████████████▌               | 384/617 [00:09<00:05, 42.71it/s]\u001b[A\n",
      " 63%|█████████████████████████▊               | 389/617 [00:09<00:05, 42.58it/s]\u001b[A\n",
      " 64%|██████████████████████████▏              | 394/617 [00:09<00:05, 42.82it/s]\u001b[A\n",
      " 65%|██████████████████████████▌              | 399/617 [00:09<00:05, 43.33it/s]\u001b[A\n",
      " 65%|██████████████████████████▊              | 404/617 [00:10<00:04, 43.69it/s]\u001b[A\n",
      " 66%|███████████████████████████▏             | 409/617 [00:10<00:04, 43.84it/s]\u001b[A\n",
      " 67%|███████████████████████████▌             | 414/617 [00:10<00:04, 43.98it/s]\u001b[A\n",
      " 68%|███████████████████████████▊             | 419/617 [00:10<00:04, 43.79it/s]\u001b[A\n",
      " 69%|████████████████████████████▏            | 424/617 [00:10<00:04, 43.57it/s]\u001b[A\n",
      " 70%|████████████████████████████▌            | 429/617 [00:10<00:04, 42.83it/s]\u001b[A\n",
      " 70%|████████████████████████████▊            | 434/617 [00:10<00:04, 42.10it/s]\u001b[A\n",
      " 71%|█████████████████████████████▏           | 439/617 [00:10<00:04, 41.29it/s]\u001b[A\n",
      " 72%|█████████████████████████████▌           | 444/617 [00:10<00:04, 40.55it/s]\u001b[A\n",
      " 73%|█████████████████████████████▊           | 449/617 [00:11<00:04, 39.94it/s]\u001b[A\n",
      " 74%|██████████████████████████████▏          | 454/617 [00:11<00:04, 39.47it/s]\u001b[A\n",
      " 74%|██████████████████████████████▍          | 458/617 [00:11<00:04, 39.04it/s]\u001b[A\n",
      " 75%|██████████████████████████████▋          | 462/617 [00:11<00:04, 38.67it/s]\u001b[A\n",
      " 76%|██████████████████████████████▉          | 466/617 [00:11<00:03, 38.40it/s]\u001b[A\n",
      " 76%|███████████████████████████████▏         | 470/617 [00:11<00:03, 38.17it/s]\u001b[A\n",
      " 77%|███████████████████████████████▍         | 474/617 [00:11<00:03, 38.10it/s]\u001b[A\n",
      " 77%|███████████████████████████████▊         | 478/617 [00:11<00:03, 38.05it/s]\u001b[A\n",
      " 78%|████████████████████████████████         | 482/617 [00:11<00:03, 38.06it/s]\u001b[A\n",
      " 79%|████████████████████████████████▎        | 486/617 [00:12<00:03, 38.16it/s]\u001b[A\n",
      " 79%|████████████████████████████████▌        | 490/617 [00:12<00:03, 38.18it/s]\u001b[A\n",
      " 80%|████████████████████████████████▊        | 494/617 [00:12<00:03, 38.09it/s]\u001b[A\n",
      " 81%|█████████████████████████████████        | 498/617 [00:12<00:03, 38.06it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▍       | 503/617 [00:12<00:02, 39.90it/s]\u001b[A\n",
      " 82%|█████████████████████████████████▊       | 508/617 [00:12<00:02, 41.20it/s]\u001b[A\n",
      " 83%|██████████████████████████████████       | 513/617 [00:12<00:02, 42.12it/s]\u001b[A\n",
      " 84%|██████████████████████████████████▍      | 518/617 [00:12<00:02, 41.81it/s]\u001b[A\n",
      " 85%|██████████████████████████████████▊      | 523/617 [00:12<00:02, 41.11it/s]\u001b[A\n",
      " 86%|███████████████████████████████████      | 528/617 [00:13<00:02, 40.33it/s]\u001b[A\n",
      " 86%|███████████████████████████████████▍     | 533/617 [00:13<00:02, 39.60it/s]\u001b[A\n",
      " 87%|███████████████████████████████████▋     | 537/617 [00:13<00:02, 38.88it/s]\u001b[A\n",
      " 88%|███████████████████████████████████▉     | 541/617 [00:13<00:01, 38.22it/s]\u001b[A\n",
      " 88%|████████████████████████████████████▏    | 545/617 [00:13<00:01, 37.76it/s]\u001b[A\n",
      " 89%|████████████████████████████████████▍    | 549/617 [00:13<00:01, 37.35it/s]\u001b[A\n",
      " 90%|████████████████████████████████████▋    | 553/617 [00:13<00:01, 37.08it/s]\u001b[A\n",
      " 90%|█████████████████████████████████████    | 557/617 [00:13<00:01, 36.85it/s]\u001b[A\n",
      " 91%|█████████████████████████████████████▎   | 561/617 [00:14<00:01, 36.67it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▌   | 565/617 [00:14<00:01, 36.68it/s]\u001b[A\n",
      " 92%|█████████████████████████████████████▊   | 569/617 [00:14<00:01, 36.72it/s]\u001b[A\n",
      " 93%|██████████████████████████████████████   | 573/617 [00:14<00:01, 36.60it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▎  | 577/617 [00:14<00:01, 36.39it/s]\u001b[A\n",
      " 94%|██████████████████████████████████████▌  | 581/617 [00:14<00:00, 36.34it/s]\u001b[A\n",
      " 95%|██████████████████████████████████████▊  | 585/617 [00:14<00:00, 36.24it/s]\u001b[A\n",
      " 95%|███████████████████████████████████████▏ | 589/617 [00:14<00:00, 36.16it/s]\u001b[A\n",
      " 96%|███████████████████████████████████████▍ | 593/617 [00:14<00:00, 36.06it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▋ | 597/617 [00:15<00:00, 35.88it/s]\u001b[A\n",
      " 97%|███████████████████████████████████████▉ | 601/617 [00:15<00:00, 35.83it/s]\u001b[A\n",
      " 98%|████████████████████████████████████████▏| 605/617 [00:15<00:00, 36.23it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▍| 609/617 [00:15<00:00, 36.52it/s]\u001b[A\n",
      " 99%|████████████████████████████████████████▋| 613/617 [00:15<00:00, 36.69it/s]\u001b[A\n",
      "100%|█████████████████████████████████████████| 617/617 [00:15<00:00, 39.67it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding bounding boxes with YOLO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "HIP out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 63.98 GiB of which 0 bytes is free. Of the allocated memory 756.50 KiB is allocated by PyTorch, and 1.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m lucas_kanade_video(frames_path, tracked_labels_path, \u001b[38;5;241m4\u001b[39m, corners)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinding bounding boxes with YOLO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m first_3_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtracking_with_bounding_boxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mYOLO_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myolo_boxes_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracked_labels_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_boxes_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_boxes_height\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoing through YOLO predictions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     25\u001b[0m creating_missing_bboxes(yolo_boxes_path, bboxes_path, first_3_idx, id_length)\n",
      "Cell \u001b[0;32mIn[5], line 17\u001b[0m, in \u001b[0;36mtracking_with_bounding_boxes\u001b[0;34m(model, video_frames_path, video_bboxes_path, tracked_labels_path, add_to_boxes_width, add_to_boxes_height)\u001b[0m\n\u001b[1;32m     14\u001b[0m frame \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(cv2\u001b[38;5;241m.\u001b[39mimread(frame_path), cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     15\u001b[0m height, width, channels \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m---> 17\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1920\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                      \u001b[49m\u001b[43miou\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mpersist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mcls\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m     24\u001b[0m bboxes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxywhn\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/ultralytics/engine/model.py:593\u001b[0m, in \u001b[0;36mModel.track\u001b[0;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[1;32m    592\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 593\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/ultralytics/engine/model.py:542\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor:\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m (predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m\"\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_cli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs, args)\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/ultralytics/engine/predictor.py:384\u001b[0m, in \u001b[0;36mBasePredictor.setup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msetup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    377\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m    Initialize YOLO model with given parameters and set it to evaluation mode.\u001b[39;00m\n\u001b[1;32m    379\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;124;03m        verbose (bool): Whether to print verbose output.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoBackend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice  \u001b[38;5;66;03m# update device\u001b[39;00m\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfp16  \u001b[38;5;66;03m# update half\u001b[39;00m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/ultralytics/nn/autobackend.py:162\u001b[0m, in \u001b[0;36mAutoBackend.__init__\u001b[0;34m(self, weights, device, dnn, data, fp16, batch, fuse, verbose)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# In-memory PyTorch model\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nn_module:\n\u001b[0;32m--> 162\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fuse:\n\u001b[1;32m    164\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfuse(verbose\u001b[38;5;241m=\u001b[39mverbose)\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1355\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1353\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/ultralytics/nn/tasks.py:264\u001b[0m, in \u001b[0;36mBaseModel._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    Apply a function to all tensors in the model that are not parameters or registered buffers.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m        (BaseModel): An updated BaseModel object.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Detect()\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    267\u001b[0m         m, Detect\n\u001b[1;32m    268\u001b[0m     ):  \u001b[38;5;66;03m# includes all Detect subclasses like Segment, Pose, OBB, WorldDetect, YOLOEDetect, YOLOESegment\u001b[39;00m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/torch/nn/modules/module.py:915\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 915\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    918\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    926\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/torch/nn/modules/module.py:942\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 942\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    945\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/virEnvs/pipeline/lib/python3.11/site-packages/torch/nn/modules/module.py:1341\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1336\u001b[0m             device,\n\u001b[1;32m   1337\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1338\u001b[0m             non_blocking,\n\u001b[1;32m   1339\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1340\u001b[0m         )\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: HIP out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 63.98 GiB of which 0 bytes is free. Of the allocated memory 756.50 KiB is allocated by PyTorch, and 1.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_HIP_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "id_length = 6\n",
    "padding_up_down = 10 # How many pixels we add beyond bounding box pixels (10 means 5 pixels for each side)\n",
    "padding_sides = 10\n",
    "add_to_boxes_height = 10 # saving little bit bigger boxes than yolo predicts\n",
    "add_to_boxes_width = 10 # saving little bit bigger boxes than yolo predicts\n",
    "\n",
    "\n",
    "print(\"Change the fps of the video\")\n",
    "video_changed_fps = VideoFileClip(video)\n",
    "video_changed_fps.write_videofile(video_changed_fps_path, fps=24)\n",
    "\n",
    "print(\"Saving video as frames\")\n",
    "save_video_as_frames(video_changed_fps_path, frames_path, id_length)\n",
    "\n",
    "print(\"Finding corners\")\n",
    "coordinates = read_in_coordinates(corner_file_path)\n",
    "corners = np.float32(np.array([[[coordinates[0], coordinates[1]]], [[coordinates[2], coordinates[3]]], [[coordinates[4], coordinates[5]]], [[coordinates[6], coordinates[7]]]]))\n",
    "lucas_kanade_video(frames_path, tracked_labels_path, 4, corners)\n",
    "\n",
    "print(\"Finding bounding boxes with YOLO\")\n",
    "first_3_idx = tracking_with_bounding_boxes(YOLO_model, frames_path, yolo_boxes_path, tracked_labels_path, add_to_boxes_width, add_to_boxes_height)\n",
    "\n",
    "print(\"Going through YOLO predictions\")\n",
    "creating_missing_bboxes(yolo_boxes_path, bboxes_path, first_3_idx, id_length)\n",
    "\n",
    "print(\"Changing digits in the frames\")\n",
    "changing_digits_in_the_frames(frames_path, \n",
    "                              bboxes_path, \n",
    "                              square_digits_path, \n",
    "                              changed_frames_path, \n",
    "                              id_length, \n",
    "                              padding_up_down, \n",
    "                              padding_sides, \n",
    "                              wavepaint_model_file,\n",
    "                              wavepaint_predict)\n",
    "\n",
    "\n",
    "print(\"Creating video from frames\")\n",
    "creating_video_from_frames(video_changed_fps_path, changed_frames_path, video_frames)\n",
    "\n",
    "# Creating the audio file\n",
    "getting_video_audio(video_changed_fps_path, audio)\n",
    "\n",
    "print(\"Adding audio to the video\")\n",
    "adding_audio_to_a_video(video_frames, audio, video_final)\n",
    "\n",
    "print(\"Removing unnecessary files\")\n",
    "remove_files(video_changed_fps_path, video_frames, audio, frames_path, yolo_boxes_path, bboxes_path, square_digits_path, changed_frames_path, tracked_labels_path)\n",
    "\n",
    "print(\"Video with changed digits is ready\")\n",
    "\n",
    "end_time = time.time()\n",
    "run_time = end_time - start_time\n",
    "print(\"This video changing took \" + str(run_time) + \" seconds aka \" + str(run_time/60) + \" minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e70cfe-c1d1-43da-8c8e-93d38db7c565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
