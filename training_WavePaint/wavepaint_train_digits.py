
import torch, torchvision
import torch.nn as nn
import numpy as np
import cv2, sys, os, time, lpips, argparse 
from tqdm import tqdm
from torchinfo import summary
from torchmetrics.functional import peak_signal_noise_ratio
from torchmetrics.functional import structural_similarity_index_measure
from saicinpainting.training.data.datasets import make_default_train_dataloader, make_default_val_dataloader
from model import WavePaint
import torch.optim as optim
import time



parser = argparse.ArgumentParser()

#parser.add_argument("-img", "--img_save_folder", default="CelebHQ_Model_generated_images", help = "Path to save images generated by model")

parser.add_argument("-b", "--batch_size", default=16, help = "Batch Size")
parser.add_argument("-d", "--cuda_device", default=0, help = "Defines, which cuda we use")
parser.add_argument("-t", "--train_data", default="data/train", help = "Path to train data")
parser.add_argument("-v", "--val_data", default="data/val", help = "Path to val data")
parser.add_argument("-m", "--model_path", default="model.pth", help = "Path to saved model to continue training")
parser.add_argument("-e", "--epoch_adam", default=20, help = "Number of epochs with the Adam optimizer")
parser.add_argument("-E", "--epoch_sgd", default=20, help = "Number of epochs with the SGD optimizer")
parser.add_argument("-f", "--file_name", default="train_info.txt", help = "File to save the training info.")

args = parser.parse_args()

#img_save_folder_loc	= str(args.img_save_folder)
TrainBatchSize		= int(args.batch_size)
cuda_device         = args.cuda_device
device 				= torch.device("cuda:"+str(cuda_device) if torch.cuda.is_available() else "cpu")
loss_fn 			= lpips.LPIPS(net='alex').to(device)
train_data          = args.train_data
val_data            = args.val_data
model_path          = args.model_path
epoch_adam          = int(args.epoch_adam)
epoch_sgd           = int(args.epoch_sgd)
train_info_file     = args.file_name

print("Cuda device " +str(cuda_device))
print("Cuda device " +str(device))



TrainDataLoaderConfig={'indir': train_data, 'out_size': 256, 'mask_gen_kwargs': {'irregular_proba': 1, 'irregular_kwargs': {'max_angle': 4, 'max_len': 200, 'max_width': 100, 'max_times': 5,  'min_times': 1}, 'box_proba': 1, 'box_kwargs': {'margin': 10, 'bbox_min_size': 30, 'bbox_max_size': 150, 'max_times': 4, 'min_times': 1}, 'segm_proba': 0}, 'transform_variant': 'no_augs', 
                                                'dataloader_kwargs': {'batch_size': TrainBatchSize, 'shuffle': True, 'num_workers': 2}}  


train_loader = make_default_train_dataloader(**TrainDataLoaderConfig)

ValDataLoaderConfig = {	'dataloader_kwargs': {	'batch_size'	: int(TrainBatchSize/2), 
                                                'shuffle'		: False, 
                                                'num_workers'	: 4}}

eval_loader	= make_default_val_dataloader( indir	= val_data,
                                        img_suffix	= ".png", 
                                        out_size	= 256,
                                        **ValDataLoaderConfig) 


### MODEL ARCHITECTURE ###

base_path="WavePaint"

NUM_MODULES 	= 6
NUM_BLOCKS		= 4 
MODEL_EMBEDDING	= 128 


model = WavePaint(
    num_modules			= NUM_MODULES,
    blocks_per_module 	= NUM_BLOCKS,
    mult 				= 2,
    ff_channel 			= MODEL_EMBEDDING,
    final_dim 			= MODEL_EMBEDDING,
    dropout 			= 0.5
).to(device)


PATH = model_path
model.load_state_dict(torch.load(model_path))

#summary(model, input_size= [(1, 3, 256,256),(1, 1,256,256)], col_names= ("input_size","output_size","num_params"), depth = 6)
###########################################################################################################################################



def calc_curr_performance(model,valloader, epoch = 0, full_dataset=True):
    
    Losses = {"L1":[], "L2":[], "PSNR":[], "SSIM":[], "LPIPS":[]}
    
    for i, data in enumerate(tqdm(valloader)):

        if not full_dataset and i>2:
            break

        img, mask 		= torch.Tensor(data["image"].to(device)), torch.Tensor(data["mask"].to(device))
        ground_truth 	= img.clone()
        
        img[:, :, :]	= img[:, :, :] * (1 - mask)
        masked_img	  	= img

        out			 	= model(masked_img, mask)
        losses		  	= EvalMetrics(out, ground_truth)

        for metric in losses.keys():
            Losses[metric].append(losses[metric])

    #cv2.imwrite(img_save_folder_loc+"/"+"eval_input"+str(epoch)+".png",cv2.cvtColor(masked_img[1].permute([1,2,0]).cpu().detach().numpy()*255, cv2.COLOR_RGB2BGR))
    #cv2.imwrite(img_save_folder_loc+"/"+"eval_output"+str(epoch)+".png",cv2.cvtColor(out[1].permute([1,2,0]).cpu().detach().numpy()*255, cv2.COLOR_RGB2BGR))

    return Losses

def EvalMetrics(out,gt):
    losses={}
    
    
    losses["L1"]	=  nn.L1Loss()(out,gt).mean().item()
    losses["L2"]	=  nn.MSELoss()(out,gt).mean().item()
    losses["PSNR"]  =  peak_signal_noise_ratio(out,gt).mean().item()
    losses["SSIM"]  =  structural_similarity_index_measure(out,gt).mean().item()
    losses["LPIPS"] =  loss_fn(gt,out).mean().item()

    return losses

class HybridLoss(nn.Module):
    def __init__(self, alpha = 0.5):
        super(HybridLoss, self).__init__()
        self.alpha=alpha
        
    def forward(self, x, y):
    
        l_lpips = loss_fn(x, y).mean()
        
        losses = l_lpips + (1 - self.alpha)*(nn.L1Loss()(x, y)) + (self.alpha*(nn.MSELoss()(x, y)))

        return losses*10

scaler 		= torch.cuda.amp.GradScaler()
optimizer 	= optim.AdamW(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)
criterion 	= HybridLoss().to(device)


prev_loss	 = float("inf")
Losses 		 = calc_curr_performance(model,eval_loader)
Final_losses = {}
for metric in Losses.keys():
    Final_losses[metric] = round(np.array(Losses[metric]).mean(), 4)


print("="*100)
print("")
print("TRAINING MODEL: " +str(model_path))
print("Training set size: " +str(len(train_loader)*int(TrainBatchSize)))
print("Validation set size: " +str(len(eval_loader)*int(TrainBatchSize/2)))
print("")
print("="*100)
print("####PRE TRAIN:",Final_losses)
print("="*100)


# Saving losses into a file
losses_file = open(train_info_file, "a")


epoch 	= 0
counter = 0
while epoch < epoch_adam:
    index 			= 0
    epoch_loss  	= 0
    

    model.train()

    with tqdm(train_loader, unit="batch") as tepoch:
        tepoch.set_description(f"Epoch {epoch+1}")

        for i, data in enumerate(tepoch, 0):

            image, mask = data["image"].to(device), data["mask"].to(device)
            target		= image.clone() ## expected output

            image[:, :, :] 	= image[:, :, :] * (1 - mask)
            inputs 			= image
            
            optimizer.zero_grad()
            outputs = model(inputs, mask)
            
            with torch.cuda.amp.autocast():
                loss = criterion(outputs, target)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()


            epoch_loss += loss.detach() 

            tepoch.set_postfix_str(f" loss : {epoch_loss/len(train_loader):.4f}")

        print(f"Epoch : {epoch+1} - epoch_loss: {epoch_loss}")


    counter += 1
    model.eval()
    if epoch % 1 == 0:

        Losses = calc_curr_performance(model,eval_loader,epoch)
        Final_losses = {}
        losses_string = ""
        for metric in Losses.keys():
            Final_losses[metric] = round(np.array(Losses[metric]).mean(), 4)
            losses_string += str(metric) + " "
            losses_string += str(round(np.array(Losses[metric]).mean(), 4))  + " "

        print("####epoch ",epoch+1,"Testing: ",Final_losses)
        print(losses_string)

        losses_file = open(train_info_file, "a")
        losses_file.write("EPOCH " +str(epoch+1) + " losses" + "\n")
        losses_file.write(losses_string + "\n")
        losses_file.close()

        if prev_loss >= Final_losses["LPIPS"]:
            torch.save(model.state_dict(), PATH)
            prev_loss = Final_losses["LPIPS"]
            print("saving chkpoint")
            counter = 0

    
    epoch += 1

print("Switching to SGD")
model.load_state_dict(torch.load(PATH))
optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)
counter = 0
while epoch < epoch_adam + epoch_sgd:
    index 		= 0
    epoch_loss  = 0
    
    model.train()

    with tqdm(train_loader, unit="batch") as tepoch:
        tepoch.set_description(f"Epoch {epoch+1}")

        for i, data in enumerate(tepoch, 0):

            image, mask = data["image"].to(device), data["mask"].to(device)
            target		= image.clone() ## expected output

            image[:, :, :] 	= image[:, :, :] * (1 - mask)
            inputs 			= image
            
            optimizer.zero_grad()
            outputs = model(inputs, mask)
            
            with torch.cuda.amp.autocast():
                loss = criterion(outputs, target)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()


            epoch_loss += loss.detach() 

            tepoch.set_postfix_str(f" loss : {epoch_loss/len(train_loader):.4f}" )

        print(f"Epoch : {epoch+1} - epoch_loss: {epoch_loss}" )


    counter += 1
    model.eval()
    if epoch % 1 == 0:

        Losses = calc_curr_performance(model,eval_loader,epoch)
        Final_losses = {}
        losses_string = ""
        for metric in Losses.keys():
            Final_losses[metric] = round(np.array(Losses[metric]).mean(), 4)
            losses_string += str(metric) + " "
            losses_string += str(round(np.array(Losses[metric]).mean(), 4))  + " "

        print("####epoch ",epoch+1,"Testing: ",Final_losses)

        losses_file = open(train_info_file, "a")
        losses_file.write("EPOCH " +str(epoch+1) + " losses" + "\n")
        losses_file.write(losses_string + "\n")
        losses_file.close()


        if prev_loss >= Final_losses["LPIPS"]:
            torch.save(model.state_dict(), PATH)
            prev_loss = Final_losses["LPIPS"]
            print("saving chkpoint")
            counter = 0

    
    epoch += 1

print('Finished Training')

model.load_state_dict(torch.load(PATH))
Losses 		 = calc_curr_performance(model, eval_loader)
Final_losses = {}
for metric in Losses.keys():
    Final_losses[metric] = round(np.array(Losses[metric]).mean(), 4)

print("="*100)
print("####BEST MODEL:",Final_losses)
print("="*100)


